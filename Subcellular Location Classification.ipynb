{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Image classification\n",
      "\n",
      "Now, let's tackle a slightly more complex problem: image classification!\n",
      "\n",
      "First, the basics:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import mahotas as mh\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "from IPython.html.widgets import interact, fixed\n",
      "plt.rcParams['figure.figsize'] = (10.0, 8.0) # 10 x 8 inches\n",
      "plt.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The data\n",
      "\n",
      "This is a *subcellular location* problem.\n",
      "\n",
      "The data is organized by directories:\n",
      "\n",
      "    data/\n",
      "        nuclear/\n",
      "        cytoplasmic\n",
      "\n",
      "The images are stored in JPEG format (which is a **terrible idea for scientific uses**, but this is a demo, and JPEG downloads faster).\n",
      "\n",
      "We can use the ``glob`` to get the same effect as on the command line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "images = glob('data/nuclear/*jpeg')\n",
      "images += glob('data/cytoplasmic/*jpeg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's just look at some basic stats on the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Number of images: {}\".format(len(images)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_nuclear = sum(('nuclear' in im) for im in images)\n",
      "print(\"Number of nuclear images: {}\".format(n_nuclear))\n",
      "print(\"Number of cytoplasmic images: {}\".format(len(images)-n_nuclear))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@interact(n=(0,len(images)-1))\n",
      "def look_at_images(n):\n",
      "    im = images[n]\n",
      "    if 'nuclear' in images[n]:\n",
      "        label = 'nuclear'\n",
      "    else:\n",
      "        label = 'cytoplasmic'\n",
      "    print(\"Image {} is {}\".format(n, label))\n",
      "    plt.imshow(mh.stretch(mh.imread(im)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's look at some images"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Classification using features\n",
      "\n",
      "The general idea of classification using features is illustrated in the diagram below\n",
      "\n",
      "1. take images where the label is known\n",
      "2. From each compute a small number of features (*small* means *less than 1000*)\n",
      "3. Use a **classifier** to smartly compare new images to the labeled ones: \n",
      "\n",
      "\n",
      "![Basic classification overview](https://upload.wikimedia.org/wikipedia/commons/c/c5/SubcellularLocationClassification.png)\n",
      "\n",
      "### Computing features\n",
      "\n",
      "Mahotas makes it pretty easy to compute features. We are just going to use *Haralick features* in this example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "im = images[0]\n",
      "im = mh.imread(im)\n",
      "print(mh.features.haralick(im, return_mean_ptp=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Computing all features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "features = []\n",
      "is_nuclear = []\n",
      "for im in images:\n",
      "    is_nuclear.append('nuclear' in im)\n",
      "    im = mh.imread(im)\n",
      "    features.append(mh.features.haralick(im, return_mean_ptp=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We convert to numpy for convenience"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "features = np.array(features)\n",
      "is_nuclear = np.array(is_nuclear)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We import scikit-learn and will use a random forest classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import ensemble, cross_validation\n",
      "clf = ensemble.RandomForestClassifier()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now use cross-validation to obtain predictions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = cross_validation.cross_val_predict(clf, features, is_nuclear)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acc = np.mean(predictions == is_nuclear)\n",
      "print(\"Accuracy: {:.2%}\".format(acc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Looking at the errors\n",
      "\n",
      "We can look at the images where the classifier makes mistakes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "errors = np.where(predictions != is_nuclear)[0]\n",
      "@interact(n=(0,len(errors)-1))\n",
      "def spot_error(n):\n",
      "    err = errors[n]\n",
      "    im = images[err]\n",
      "    label = 'nuclear' if is_nuclear[err] else 'cytoplasmic'\n",
      "    print(\"Image {} should have been identified as {} (was not)\".format(err, label))\n",
      "    plt.imshow(mh.imread(im))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "## Final notes\n",
      "\n",
      "This is not a great classification method (80% is not awful, but *nuclear* vs *cytoplasmic* is an easy problem [try ER vs cytoplasmic if you want a hard problem]). In fact, we could hope to obtain close to 100% accuracy with these data with good methods.\n",
      "\n",
      "A large improvement could be obtained by using more features, which capture other aspects of the images, by taking into account the DNA channel (which we ignored in this exercise), or by other ides\n",
      "\n",
      "The paper [Determining the subcellular location of new proteins from microscope images using local features](http://dx.doi.org/10.1093/bioinformatics/btt392) by Coelho et al. introduced these data and presented much better methods."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}